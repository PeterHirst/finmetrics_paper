---
title: "README"
author: "PA HIRST"
date: "December 3, 2018"
output: html_document
---
# Purpose
To walk you through the coding and functions for my financial econometrics paper, which models currency co-movement during different periods of global uncertainty. Please refer to the "Hirst.pdf" file for the full paper. This README is purely an account of the functions and code.
I have included the simple stuff as well, such as loading data.

## Load data

Firstly, this function is responsible for loading some core packages needed for the project code:
```{r load packages}

LoadPackages <- function(){
  
  library(rmsfuns)
  
  corepacks <- c("tidyverse", "RcppRoll", "ggplot2", "lubridate",
                 "ggthemes", "purrr", "tbl2xts", "xts", "MTS", "devtools", "rugarch", "forecast", "PerformanceAnalytics", "xtable")
  
  load_pkg(corepacks)
  
}
```


Then, load the data and subset the sample (pre and post-crisis).
```{r load data & subset}
# -------------------------------------------------------- Set Parameters ------------------------------------------------------

# create the start and end dates of the two periods
SampleOneStartDate <- ymd(20020101)
SampleOneEndDate <- ymd(20080101)
SampleTwoStartDate <- ymd(20100101)
SampleTwoEndDate <- today() # this part allows the paper to be fully updated as the data is updated on a daily basis.


# -------------------------------------------------------- Load data ------------------------------------------------------

# creates the sample of countries and places them in groups (BRICS, etc)
cur.sample <-
  read_csv(paste0(getwd(), "/settings/Currencies.csv")) %>% 
  mutate(Ticker = paste0(Ticker, " Curncy"))

cur.sample.tickers <- cur.sample %>% pull(Ticker)

# loads the currency data
data.cur <-
  read_rds(paste0(getwd(), "/Data/Cncy.rds")) %>% 
  mutate(Period = ifelse(date >= SampleOneStartDate & date <= SampleOneEndDate, "Period_1",
                         ifelse(date >= SampleTwoStartDate & date <= SampleTwoEndDate, "Period_2", "Other"))) %>% 
  filter(Period %in% c("Period_1", "Period_2")) %>% filter(Ticker %in% cur.sample.tickers) 

# loads the data which is to be stratified (global uncertainty indices)
data.str <-
    read_rds(paste0(getwd(), "/Data/Strat_Series.rds"))
```

## Functions

The function below calculates the weekly returns of the currencies in our sample, simply feed the data into the function and the returns are calculated:
```{r weekly return function}
WeeklyReturnFunction <- function(data){
  
  df <-
    data %>% arrange(date, Ticker) %>% group_by(Period, Ticker) %>%
    filter(format(date, "%a") == "Wed") %>% 
    mutate(Weekly_Return = Value / lag(Value) - 1) %>% 
    mutate(Weekly_Return = coalesce(Weekly_Return, 0)) %>%  # Set NA to Zero.
    ungroup()
  
  df # print the dataframe 
  
}

```

In order to stratify the data, the following functions are written. Most of the explanations are contained in the code chunks, as comments. In our paper, we stratify the CBOE Volatility Index (VIX).

This function creates the stratification dates, which will allow us to compare the sample correlations with those during periods of high/low uncertainty:
```{r stratification code}
CreateIVQuintileStratificationDates <- function(data, DistributionSplit, SampleOneStartDate, SampleOneEndDate, SampleTwoStartDate, SampleTwoEndDate, MinTradeDays, NoTradeDaysToMinusBeg){
  
  # This function returns dates for periods of high and low implied volatility according to quintiles (Top 20% and bottom 20% of distribution)
  # It is only suitable for implied and realized volatility indices/series
  # The distribution split is parameterized so you can change it from quintiles to quantiles for example.
  # MinTradeDays -- Minimum number of trading days the VIX must breach to top or bottom quntile
  # NoTradeDaysToMinusBeg -- number of trading days to minus at the beginning to allow correlation to adjust
  
  # INPUT data -- a dataframe with the series eg. VIX that is in tidy format and looks like this: date, Ticker, Value
  
  Upper <- 1 - DistributionSplit

  df.strat <-
    data %>% filter(!is.na(Value)) %>%
    mutate(Period = ifelse(date >= SampleOneStartDate & date <= SampleOneEndDate, "Period_1", 
                           ifelse(date >= SampleTwoStartDate & date <= SampleTwoEndDate, "Period_2", "Other"))) %>% 
    filter(Period %in% c("Period_1", "Period_2")) %>% 
    group_by(Period) %>% 
    arrange(date) %>% 
    mutate(Q1 = quantile(Value, probs = DistributionSplit, na.rm = TRUE),
           Q2 = quantile(Value, probs = Upper, na.rm = TRUE)) %>% 
    mutate(State = ifelse(Value < Q1, "Low",
                          ifelse(Value < Q2, "Middle", "High"))) %>% 
    mutate(Change = ifelse(State != lag(State), row_number(), NA)) %>% 
    mutate(Change = ifelse(date == first(date), 1, Change)) %>% 
    tidyr::fill(Change, .direction = "down") %>% filter(State != "Middle") %>% 
    group_by(Period, Change) %>% mutate(NoTradingDays = n(), RowNum = row_number()) %>% 
    ungroup() %>% filter(NoTradingDays >= MinTradeDays) %>% filter(RowNum >= NoTradeDaysToMinusBeg) %>% 
    select(date, Ticker, Period, State)
  
  df.strat  
  
}
```

This function then uses the stratification function above, to plot the VIX and then shade the stratified dates. These dates are for the top (high VIX) and bottom (low VIX) quantiles:
```{r Strat plot}
CreateVIXStratPlot <- function(data, DistributionSplit, SampleOneStartDate, SampleOneEndDate, SampleTwoStartDate, SampleTwoEndDate, MinTradeDays, NoTradeDaysToMinusBeg, TickerToPlot){
  
  Upper <- 1 - DistributionSplit
  
  data <-
    data %>% 
    filter(!is.na(Value)) %>%
    filter(Ticker == TickerToPlot)    
  
  data.q <-
    data %>% 
    mutate(Period = ifelse(date >= SampleOneStartDate & date <= SampleOneEndDate, "Period_1", 
                           ifelse(date >= SampleTwoStartDate & date <= SampleTwoEndDate, "Period_2", "Other"))) %>% 
    filter(Period %in% c("Period_1", "Period_2")) %>% 
    group_by(Period) %>% 
    arrange(date) %>% 
    mutate(Q1 = quantile(Value, probs = DistributionSplit, na.rm = TRUE),
           Q2 = quantile(Value, probs = Upper, na.rm = TRUE)) %>% 
    mutate(State = ifelse(Value < Q1, "Low",
                          ifelse(Value < Q2, "Middle", "High"))) %>% 
    ungroup()
  
  df.strat <-
    data.q %>% 
    group_by(Period) %>% 
    mutate(Change = ifelse(State != lag(State), row_number(), NA)) %>% 
    mutate(Change = ifelse(date == first(date), 1, Change)) %>% 
    tidyr::fill(Change, .direction = "down") %>% filter(State != "Middle") %>% 
    group_by(Period, Change) %>% mutate(NoTradingDays = n(), RowNum = row_number()) %>% 
    ungroup() %>% filter(NoTradingDays >= MinTradeDays) %>% filter(RowNum >= NoTradeDaysToMinusBeg)
  
  df.1 <-
    df.strat %>% filter(Period == "Period_1") %>% 
    group_by(Change) %>% filter(date == first(date) | date == last(date)) %>% 
    mutate(DateType = ifelse(date == first(date), "StartDate", "EndDate")) %>% 
    select(Change, date, DateType) %>% 
    spread(DateType, date) %>% ungroup()
  
  df.2 <-
    df.strat %>% filter(Period == "Period_2") %>% 
    group_by(Change) %>% filter(date == first(date) | date == last(date)) %>% 
    mutate(DateType = ifelse(date == first(date), "StartDate", "EndDate")) %>% 
    select(Change, date, DateType) %>% 
    spread(DateType, date) %>% ungroup()
  
  g <-
    ggplot(data %>% filter(date >= SampleOneStartDate)) + geom_line(aes(x = date, y = Value), color = "steelblue") + 
    geom_line(data = data.q %>% filter(Period == "Period_1"), aes(date, Q1)) +
    geom_line(data = data.q %>% filter(Period == "Period_2"), aes(date, Q1)) +
    geom_line(data = data.q %>% filter(Period == "Period_1"), aes(date, Q2)) +
    geom_line(data = data.q %>% filter(Period == "Period_2"), aes(date, Q2)) +
    geom_rect(data = df.1, aes(xmin = StartDate, xmax = EndDate, ymin=-Inf, ymax=+Inf), fill='red', alpha=0.2) +
    geom_rect(data = df.2, aes(xmin = StartDate, xmax = EndDate, ymin=-Inf, ymax=+Inf), fill='red', alpha=0.2) +
    labs(x = NULL, y = NULL) +
    theme_bw() 
  
  g
  
}
```

## DCC-GARCH

This code calculates the conditional volatiliies in preparation for the DCC estimations:
```{r VOL calcs}

rtn.1 <- Weekly_Ret %>% filter(Period == "Period_1") %>% mutate(Ticker = gsub(" Curncy", "", Ticker)) %>% 
  # take out China and Malaysia -- currencies pegged until about 2005
  filter(!Ticker %in% c("CNY")) %>% filter(!Ticker %in% c("MYR")) %>% 
  select(-Period, -Name, -Value) %>% spread(Ticker, Weekly_Return) %>% tbl_xts()

rtn.2 <- Weekly_Ret %>% filter(Period == "Period_2") %>% mutate(Ticker = gsub(" Curncy", "", Ticker)) %>%   
  select(-Period, -Name, -Value) %>% spread(Ticker, Weekly_Return) %>% tbl_xts()

rtn.1 <- rtn.1[-1,]
rtn.2 <- rtn.2[-1,]

# Center the data:
rtn.1 <- scale(rtn.1,center=T,scale=F)
rtn.2 <- scale(rtn.2,center=T,scale=F)

# And clean it using Boudt's technique:
rtn.1 <- Return.clean(rtn.1, method = c("none", "boudt", "geltner")[2], alpha = 0.01)
rtn.2 <- Return.clean(rtn.2, method = c("none", "boudt", "geltner")[2], alpha = 0.01)

# DCCPre
DCCPre.1 <- dccPre(rtn.1, include.mean = T, p = 0)
names(DCCPre.1)
DCCPre.2 <- dccPre(rtn.2, include.mean = T, p = 0)
names(DCCPre.2)

# Change to usable xts
Vol.1 <- DCCPre.1$marVol
colnames(Vol.1) <- colnames(rtn.1)

Vol.2 <- DCCPre.2$marVol
colnames(Vol.2) <- colnames(rtn.2)

#======================================================
# VOLS
# =====================================================

# create the df of volatilities
vol.df <-
  bind_rows(
    
    data.frame( cbind( date = as.Date(index(rtn.1)), Vol.1)) %>% # Add date column which dropped away...
      mutate(date = as.Date(date)) %>% tbl_df() %>% gather(Ticker, Sigma, -date) %>% 
      mutate(Period = "Period 1"),
    
    data.frame( cbind( date = as.Date(index(rtn.2)), Vol.2)) %>% # Add date column which dropped away...
      mutate(date = as.Date(date)) %>% tbl_df() %>% gather(Ticker, Sigma, -date) %>% 
      mutate(Period = "Period 2")  ) %>% 
  left_join(., cur.sample %>% mutate(Ticker = gsub(" Curncy", "", Ticker)), by = "Ticker")
```

The code contained in this code chunk is used to estimate the dynamic conditional correlations between the ZAR and other currencies in the sample:
```{r DCC calcs}

#==============================================================================
# DCC
# =============================================================================
StdRes.1 <- DCCPre.1$sresi
StdRes.2 <- DCCPre.2$sresi # save the residuals

detach("package:rmsfuns", unload=TRUE)
detach("package:tidyverse", unload=TRUE)
detach("package:tbl2xts", unload=TRUE)

# The DCC estimations take a while (I suggest a cup of coffee in the meantime)
DCC.1 <- dccFit(StdRes.1, type="Engle")
DCC.2 <- dccFit(StdRes.2, type="Engle")

library(rmsfuns)
load_pkg(c("tidyverse", "tbl2xts"))

Rhot.1 <- DCC.1$rho.t
Rhot.2 <- DCC.2$rho.t

# Renaming function (see code cunk below for the function that renames columns in the correlation df)
source("code/renamingdcc.R")

# To see if the function works
Rhot.1 <-
  renamingdcc(ReturnSeries = rtn.1, DCC.TV.Cor = Rhot.1)

Rhot.2 <-
  renamingdcc(ReturnSeries = rtn.2, DCC.TV.Cor = Rhot.2)

# Create the correlation dataframe
df.corr <-
  bind_rows(
    Rhot.1 %>% mutate(Period = "Period 1"),
    Rhot.2 %>% mutate(Period = "Period 2")) %>%
  left_join(., cur.sample %>% mutate(Pairs = gsub(" Curncy", "", Ticker)) %>% 
              mutate(Pairs = paste0("ZAR_", Pairs)), by = "Pairs") %>% filter(!is.na(Country)) %>% 
  filter(Pairs != "ZAR_ZAR")

```

```{r renaming DCC}
renamingdcc <- function(ReturnSeries, DCC.TV.Cor) {
  
  ncolrtn <- ncol(ReturnSeries)
  namesrtn <- colnames(ReturnSeries)
  paste(namesrtn, collapse = "_")
  
  nam <- c()
  xx <- mapply(rep, times = ncolrtn:1, x = namesrtn)
  
  # Design a nested for loop to save the names corresponding to the columns of interest.
  
  
  nam <- c()
  for (j in 1:(ncolrtn)) {
    for (i in 1:(ncolrtn)) {
      nam[(i + (j-1)*(ncolrtn))] <- paste(xx[[j]][1], xx[[i]][1], sep="_")
    }
  }
  
  colnames(DCC.TV.Cor) <- nam
  
  # So to plot all the time-varying correlations wrt SBK:
  # First append the date column that has (again) been removed...
  DCC.TV.Cor <- 
    data.frame( cbind( date = as.Date(index(ReturnSeries)), DCC.TV.Cor)) %>% # Add date column which dropped away...
    mutate(date = as.Date(date)) %>% tbl_df() 
  
  DCC.TV.Cor <- DCC.TV.Cor %>% gather(Pairs, Rho, -date)
  
  DCC.TV.Cor
  
}
```

To plot the volatilities, by group of countries (i.e., BRICS, Asia, etc):
```{r VOL plots}
# BRICS
ggplot(vol.df %>% filter(Group == "BRICS")) + 
  geom_line(aes(x = date, y = Sigma, color = Country), alpha = 0.6) + 
  theme_bw() + facet_wrap(~Period, scales = "free") +
  theme(text = element_text(size = 10), axis.text = element_text(size = 10, hjust = 1, angle = 90),
        plot.title = element_text(size = 10)) +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y") + 
  ylim(0, 0.05) +
  labs(x = NULL)

# Asia
ggplot(vol.df %>% filter(Group == "Asia")) + 
  geom_line(aes(x = date, y = Sigma, color = Country), alpha = 0.6) + 
  theme_bw() + facet_wrap(~Period, scales = "free") +
  theme(text = element_text(size = 10), axis.text = element_text(size = 10, hjust = 1, angle = 90),
        plot.title = element_text(size = 10)) +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y") + 
  ylim(0, 0.05) +
  labs(x = NULL)

# South America
ggplot(vol.df %>% filter(Group == "South America")) + 
  geom_line(aes(x = date, y = Sigma, color = Country), alpha = 0.6) + 
  theme_bw() + facet_wrap(~Period, scales = "free") +
  theme(text = element_text(size = 10), axis.text = element_text(size = 10, hjust = 1, angle = 90),
        plot.title = element_text(size = 10)) +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y") + 
  ylim(0, 0.05) +
  labs(x = NULL)

# Eastern Europe
ggplot(vol.df %>% filter(Group == "Eastern Europe")) + 
  geom_line(aes(x = date, y = Sigma, color = Country), alpha = 0.6) + 
  theme_bw() + facet_wrap(~Period, scales = "free") +
  theme(text = element_text(size = 10), axis.text = element_text(size = 10, hjust = 1, angle = 90),
        plot.title = element_text(size = 10)) +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y") + 
  ylim(0, 0.05) +
  labs(x = NULL)

```

To plot the DCCs, by group of countries:
```{r DCCplots}
# BRICS
g.corr.brics <-
  ggplot(df.corr %>% filter(Group == "BRICS")) + 
  geom_line(aes(x = date, y = Rho, color = Country), alpha = 0.6) + 
  facet_wrap(~Period, scales = "free") + 
  ylim(-0.1, 1) +
  theme_bw() +
  theme(text = element_text(size = 10), axis.text = element_text(size = 10, hjust = 1, angle = 90),
        plot.title = element_text(size = 10)) +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y") +
  labs(x = NULL)

# Asia
g.corr.asia <- 
  ggplot(df.corr %>% filter(Group == "Asia")) + 
  geom_line(aes(x = date, y = Rho, color = Country), alpha = 0.6) + 
  facet_wrap(~Period, scales = "free") + 
  ylim(-0.1, 1) +
  theme_bw() +
  theme(text = element_text(size = 10), axis.text = element_text(size = 10, hjust = 1, angle = 90),
        plot.title = element_text(size = 10)) +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y") +
  labs(x = NULL)

# South America
g.corr.southamerica <-
  ggplot(df.corr %>% filter(Group == "South America")) + 
  geom_line(aes(x = date, y = Rho, color = Country), alpha = 0.6) + 
  facet_wrap(~Period, scales = "free") + 
  ylim(-0.1, 1) +
  theme_bw() +
  theme(text = element_text(size = 10), axis.text = element_text(size = 10, hjust = 1, angle = 90),
        plot.title = element_text(size = 10)) +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y") +
  labs(x = NULL)

# Eastern Europe
g.corr.easterneurope <-
  ggplot(df.corr %>% filter(Group == "Eastern Europe")) + 
  geom_line(aes(x = date, y = Rho, color = Country), alpha = 0.6) + 
  facet_wrap(~Period, scales = "free") + 
  ylim(-0.1, 1) +
  theme_bw() +
  theme(text = element_text(size = 10), axis.text = element_text(size = 10, hjust = 1, angle = 90),
        plot.title = element_text(size = 10)) +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y") +
  labs(x = NULL)
```

The final code contains the calculations needed to conclude whether the ZAR is more closely correlated with other EM currencies during high VIX (and low VIX):
```{r correlation calcs}

# Use this df for creating your tables 
df.corr.vix <-
  df.corr %>% group_by(Period, Pairs) %>% 
  mutate(Average_Period_Corr = mean(Rho, na.rm = TRUE)) %>% 
  ungroup() %>% 
  
  left_join(., 
            df.corr %>% filter(date %in% c(vix.high.period1.dates, vix.high.period2.dates)) %>% group_by(Pairs, Period) %>% 
              summarise(Average_High_VIX = mean(Rho, na.rm = TRUE)) %>% ungroup(), by = c("Pairs", "Period")) %>% 
  
  left_join(., 
            df.corr %>% filter(date %in% c(vix.low.period1.dates, vix.low.period2.dates)) %>% group_by(Pairs, Period) %>% 
              summarise(Average_Low_VIX = mean(Rho, na.rm = TRUE)) %>% ungroup(), by = c("Pairs", "Period")) %>% 
  select(Pairs, Period, Group, Country, Average_Period_Corr, Average_High_VIX, Average_Low_VIX) %>% unique() %>% 
  arrange(Group) %>% rename(Sample_average = Average_Period_Corr, HighVIX = Average_High_VIX, LowVIX = Average_Low_VIX)

# Create the high and low VIX dataframes
High.VIX <-
  CreateIVQuintileStratificationDates(data = data.str %>% filter(Ticker == "VIX Index"), 
                                      DistributionSplit = 0.2, SampleOneStartDate, SampleOneEndDate, 
                                      SampleTwoStartDate, SampleTwoEndDate, MinTradeDays = 30, NoTradeDaysToMinusBeg = 10) %>% 
  filter(State == "High") %>% 
  group_by(Change) %>% 
  filter(date == first(date) | date == last(date)) %>% 
  mutate(DateType = ifelse(date == first(date), "StartDate", "EndDate")) %>% 
  select(Change, Period, date, DateType) %>% 
  spread(DateType, date) %>% ungroup() 

Low.VIX <-
  CreateIVQuintileStratificationDates(data = data.str %>% filter(Ticker == "VIX Index"), 
                                      DistributionSplit = 0.2, SampleOneStartDate, SampleOneEndDate, 
                                      SampleTwoStartDate, SampleTwoEndDate, MinTradeDays = 30, NoTradeDaysToMinusBeg = 10) %>% 
  filter(State == "Low") %>% 
  group_by(Change) %>% 
  filter(date == first(date) | date == last(date)) %>% 
  mutate(DateType = ifelse(date == first(date), "StartDate", "EndDate")) %>% 
  select(Change, Period, date, DateType) %>% 
  spread(DateType, date) %>% ungroup() 


```

